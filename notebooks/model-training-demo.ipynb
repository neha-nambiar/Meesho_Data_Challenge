{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9991946,"sourceType":"datasetVersion","datasetId":6149566}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import f1_score\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, Optional, Union, List\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import AgglomerativeClustering\nfrom collections import defaultdict\nimport tensorflow as tf\nimport torch\nimport gc, os\nfrom tqdm import tqdm\nimport timm\nimport torch\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom typing import List, Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:21.166779Z","iopub.execute_input":"2024-11-25T22:31:21.168977Z","iopub.status.idle":"2024-11-25T22:31:39.703696Z","shell.execute_reply.started":"2024-11-25T22:31:21.168906Z","shell.execute_reply":"2024-11-25T22:31:39.703000Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif device == torch.device(\"cuda\"):\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:40.274917Z","iopub.execute_input":"2024-11-25T22:31:40.275236Z","iopub.status.idle":"2024-11-25T22:31:40.310443Z","shell.execute_reply.started":"2024-11-25T22:31:40.275210Z","shell.execute_reply":"2024-11-25T22:31:40.309472Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class UnifiedFeatureExtractor:\n    def __init__(self):\n        \"\"\"\n        Initialize feature extractors for all models.\n        \"\"\"\n        self.keras_extractors = {\n            'resnet': self.build_resnet_feature_extractor(),\n            'efficientnet': self.build_efficientnet_feature_extractor(),\n            'convnext': self.build_convnext_feature_extractor()\n        }\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    def build_resnet_feature_extractor(self):\n        base_model = tf.keras.applications.ResNet101V2(\n            input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\"\n        )\n        x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n        return tf.keras.Model(inputs=base_model.input, outputs=x)\n\n    def build_efficientnet_feature_extractor(self):\n        base_model = tf.keras.applications.EfficientNetB0(\n            input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\"\n        )\n        x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n        return tf.keras.Model(inputs=base_model.input, outputs=x)\n\n    def build_convnext_feature_extractor(self):\n        base_model = tf.keras.applications.ConvNeXtBase(\n            input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\"\n        )\n        x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n        return tf.keras.Model(inputs=base_model.input, outputs=x)\n\n    def extract_features(self, df, model_name):\n        \"\"\"\n        Extract features using models ResNet, EfficientNet and ConvNeXt.\n        \"\"\"\n        model = self.keras_extractors[model_name]\n        dataset = self.create_tf_dataset(df['image_path'].values, model_name)\n        features = model.predict(dataset, verbose=1)\n        column_name = f\"image_features_{model_name}\"\n        df[column_name] = list(features)\n        return df\n\n    def create_tf_dataset(self, image_paths, model_name):\n        \"\"\"\n        Create a TensorFlow dataset for feature extraction.\n        \"\"\"\n        def preprocess_image(image_path):\n            img_str = tf.io.read_file(image_path)\n            img = tf.image.decode_jpeg(img_str, channels=3)\n            img = tf.image.resize(img, [224, 224])\n            if model_name == 'resnet':\n                img = tf.keras.applications.resnet_v2.preprocess_input(img)\n            elif model_name == 'efficientnet':\n                img = tf.keras.applications.efficientnet.preprocess_input(img)\n            elif model_name == 'convnext':\n                img = tf.keras.applications.convnext.preprocess_input(img)\n            return img\n\n        dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n        dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n        dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n        return dataset\n\n    def extract_features(self, df, model_names):\n        \"\"\"\n        Extract features for a dataset using the models.\n        \"\"\"\n        for model_name in model_names:\n            print(f\"Extracting features with {model_name}...\")\n            df = self.extract_features(df, model_name)\n        return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:40.617278Z","iopub.execute_input":"2024-11-25T22:31:40.617582Z","iopub.status.idle":"2024-11-25T22:31:40.629308Z","shell.execute_reply.started":"2024-11-25T22:31:40.617554Z","shell.execute_reply":"2024-11-25T22:31:40.628356Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class FeatureExtractor:\n    def __init__(self, model_name: str, device: str = None):\n        \"\"\"\n        Initializes the feature extractor with a specified timm model.\n\n        Parameters:\n        - model_name: Name of the model (compatible with timm).\n        - device: Device for computation (e.g., 'cuda' or 'cpu').\n        \"\"\"\n        self.device = torch.device(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n        self.model = timm.create_model(model_name, pretrained=True, num_classes=0)  \n        self.model.to(self.device)\n        self.model.eval()\n\n        data_config = timm.data.resolve_model_data_config(self.model)\n        self.transforms = timm.data.create_transform(**data_config, is_training=False)\n\n        if self.device.type == \"cuda\":\n            self.model = self.model.half()  \n\n    def preprocess_batch(self, image_paths: List[str]) -> Tuple[torch.Tensor, List[int]]:\n        \"\"\"\n        Preprocess a batch of image paths into tensors for the model.\n\n        Parameters:\n        - image_paths: List of image file paths.\n\n        Returns:\n        - Tuple of batched tensor and a list of valid indices corresponding to the processed images.\n        \"\"\"\n        valid_images = []\n        valid_indices = []\n\n        for idx, path in enumerate(image_paths):\n            try:\n                image = Image.open(path).convert(\"RGB\")\n                transformed_image = self.transforms(image)\n                valid_images.append(transformed_image)\n                valid_indices.append(idx)\n            except Exception as e:\n                warnings.warn(f\"Error loading image {path}: {str(e)}\")\n\n        if not valid_images:\n            return None, []\n\n        batch_tensor = torch.stack(valid_images)\n        batch_tensor = batch_tensor.to(self.device, dtype=torch.half if self.device.type == \"cuda\" else torch.float)\n        return batch_tensor, valid_indices\n\n    def process_batch(self, batch_tensor: torch.Tensor) -> np.ndarray:\n        \"\"\"\n        Pass a preprocessed batch of images through the model to extract features.\n\n        Parameters:\n        - batch_tensor: A batch of preprocessed image tensors.\n\n        Returns:\n        - Numpy array of extracted features.\n        \"\"\"\n        with torch.no_grad(), torch.cuda.amp.autocast(enabled=self.device.type == \"cuda\"):\n            features = self.model.forward_features(batch_tensor)\n            features = self.model.forward_head(features, pre_logits=True)\n        return features.cpu().numpy()\n\n    def process_dataset(self, df, batch_size=8): \n        features_list = []\n        valid_indices = []\n    \n        for i in tqdm(range(0, len(df), batch_size), desc=\"Processing images\"):\n            batch_paths = df['image_path'].iloc[i:i + batch_size].tolist()\n            batch_tensor, batch_valid_indices = self.preprocess_batch(batch_paths)\n    \n            if batch_tensor is None or not batch_valid_indices:\n                continue\n    \n            batch_features = self.process_batch(batch_tensor)\n            features_list.append(batch_features)\n            valid_indices.extend([i + idx for idx in batch_valid_indices])\n    \n            if self.device.type == \"cuda\":\n                torch.cuda.empty_cache()\n    \n        all_features = np.vstack(features_list) if features_list else np.array([])\n        processed_df = df.iloc[valid_indices].copy()\n        return processed_df, all_features\n\n    def __del__(self):\n        \"\"\"\n        Destructor to clean up resources.\n        \"\"\"\n        try:\n            del self.model\n            del self.transforms\n            if self.device.type == \"cuda\":\n                torch.cuda.empty_cache()\n            gc.collect()\n        except:\n            pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:40.931081Z","iopub.execute_input":"2024-11-25T22:31:40.931686Z","iopub.status.idle":"2024-11-25T22:31:40.949305Z","shell.execute_reply.started":"2024-11-25T22:31:40.931637Z","shell.execute_reply":"2024-11-25T22:31:40.948421Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class UnifiedImputer:\n    def __init__(self, similarity_threshold=0.6, majority_threshold=0.5):\n        self.similarity_threshold = similarity_threshold\n        self.majority_threshold = majority_threshold\n\n    def compute_similarity(self, features1, features2):\n        normalized_f1 = tf.nn.l2_normalize(features1, axis=1)\n        normalized_f2 = tf.nn.l2_normalize(features2, axis=1)\n        return tf.matmul(normalized_f1, normalized_f2, transpose_b=True)\n\n    def impute_attributes(self, df, n_attributes):\n        \"\"\"\n        Impute missing attributes based on visual similarity clustering.\n        \"\"\"\n        features = np.array(list(df['image_features_resnet'].values))\n        similarities = self.compute_similarity(\n            tf.constant(features), tf.constant(features)\n        ).numpy()\n        distances = 1 - similarities\n        np.fill_diagonal(distances, 0)\n\n        clustering = AgglomerativeClustering(\n            n_clusters=None,\n            distance_threshold=1 - self.similarity_threshold,\n            affinity=\"precomputed\",\n            linkage=\"complete\"\n        )\n        clusters = clustering.fit_predict(distances)\n        cluster_groups = defaultdict(list)\n        for idx, cluster_id in enumerate(clusters):\n            cluster_groups[cluster_id].append(idx)\n\n        for cluster_id, indices in cluster_groups.items():\n            if len(indices) > 1:\n                cluster_data = df.iloc[indices]\n                for attr in [f\"attr_{i}\" for i in range(1, n_attributes + 1)]:\n                    valid_values = cluster_data[attr].dropna()\n                    if valid_values.size > 0:\n                        most_common_value = valid_values.mode()[0]\n                        df.loc[indices, attr] = df.loc[indices, attr].fillna(most_common_value)\n        return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:41.223636Z","iopub.execute_input":"2024-11-25T22:31:41.224104Z","iopub.status.idle":"2024-11-25T22:31:41.232495Z","shell.execute_reply.started":"2024-11-25T22:31:41.224069Z","shell.execute_reply":"2024-11-25T22:31:41.231544Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class BaseFashionModel:\n    def __init__(self, num_attributes: int, attr_names: Optional[List[str]] = None):\n        self.attribute_models = {}\n        self.attributes = [f'attr_{i+1}' for i in range(num_attributes)]\n        self.class_weights = {}\n        self.n_attributes = num_attributes\n        self.attr_names = attr_names if attr_names else self.attributes\n        self.best_scores = {}\n        self.attr_configs = {}  \n        self.preprocessors = {}\n\n    @staticmethod\n    def calculate_attribute_f1_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n        macro_f1 = f1_score(y_true, y_pred, average='macro')\n        micro_f1 = f1_score(y_true, y_pred, average='micro')\n        return 2 * (macro_f1 * micro_f1) / (macro_f1 + micro_f1)\n\n    def calculate_score(self, y_true: pd.DataFrame, y_pred: pd.DataFrame) -> Dict[str, float]:\n        scores = {}\n        attribute_scores = []\n\n        for i, attr_name in enumerate(self.attr_names):\n            attr_col = f'attr_{i+1}'\n            score = self.calculate_attribute_f1_score(\n                y_true[attr_col].values,\n                y_pred[attr_col].values\n            )\n            scores[attr_name] = score\n            attribute_scores.append(score)\n\n        scores['overall'] = np.mean(attribute_scores) if attribute_scores else 0.0\n        return scores\n\n    def preprocess_features(self, df: pd.DataFrame, is_training: bool = True) -> np.ndarray:\n        \"\"\"\n        General preprocessing of image features. This implementation scales and applies PCA to all image feature columns.\n\n        Parameters:\n        - df: A pandas DataFrame containing the image feature columns.\n        - is_training: If True, fit PCA and scalers; otherwise, transform using existing ones.\n\n        Returns:\n        - A numpy array containing stacked and processed feature vectors.\n        \"\"\"\n        feature_columns = [col for col in df.columns if col.startswith(\"image_features_\")]\n        scaled_features = []\n    \n        for col in feature_columns:\n            if is_training:\n                scaler = RobustScaler()\n                self.preprocessors[col] = scaler\n                scaled_feature = scaler.fit_transform(np.vstack(df[col].values))\n            else:\n                if col not in self.preprocessors:\n                    raise ValueError(f\"Scaler for column '{col}' has not been fitted yet.\")\n                scaler = self.preprocessors[col]\n                scaled_feature = scaler.transform(np.vstack(df[col].values))\n    \n            scaled_features.append(scaled_feature)\n    \n        return np.hstack(scaled_features)\n\n    def _get_attribute_config(self, attr: str) -> dict:\n        default_config = {\n            'balance_strategy': 'class_weight',\n            'model_params': {\n                'depth': 6,\n                'learning_rate': 0.1\n            }\n        }\n        return self.attr_configs.get(attr, default_config)\n\n    def _determine_sampling_strategy(self, y: np.ndarray) -> Dict:\n        class_counts = np.bincount(y)\n        max_count = np.max(class_counts)\n        strategy = {i: max_count for i in range(len(class_counts))}\n        return strategy\n\n    def _apply_sampling_strategy(self, X: np.ndarray, y: np.ndarray, strategy: str, \n                               sampling_params: Optional[Dict] = None) -> tuple:\n        if sampling_params is None:\n            sampling_params = {}\n\n        if strategy == 'smote':\n            sampling_strategy = self._determine_sampling_strategy(y)\n            sampler = SMOTE(sampling_strategy=sampling_strategy, random_state=42, **sampling_params)\n            return sampler.fit_resample(X, y)\n        elif strategy == 'smote_tomek':\n            sampler = SMOTETomek(random_state=42)\n            return sampler.fit_resample(X, y)\n        elif strategy == 'undersample':\n            sampling_strategy = 'auto'\n            sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42, **sampling_params)\n            return sampler.fit_resample(X, y)\n        else:  # No sampling\n            return X, y\n\n    def calculate_class_weights(self, y: np.ndarray, balance_strategy: str) -> Union[Dict, None]:\n        if balance_strategy != 'class_weight':\n            return None\n\n        unique_classes = np.unique(y)\n        if len(unique_classes) > 1:\n            weights = compute_class_weight(\n                class_weight='balanced',\n                classes=unique_classes,\n                y=y\n            )\n            return dict(zip(unique_classes, weights))\n        return None\n\n    def train(self, df: pd.DataFrame, validation_df: Optional[pd.DataFrame] = None, \n              epochs: int = 1000) -> 'BaseFashionModel':\n        print(\"Preparing data for training...\")\n        X = self.preprocess_features(df)\n\n        if validation_df is not None:\n            X_val = self.preprocess_features(validation_df)\n\n        print(\"Training models for each attribute...\")\n        for i, attr in enumerate(self.attributes, 1):\n            print(f\"\\nTraining model for {attr}\")\n\n            config = self._get_attribute_config(attr)\n            balance_strategy = config['balance_strategy']\n            model_params = config['model_params']\n\n            y = df[attr]\n            mask = y.notna()\n            X_attr = X[mask]\n            y_attr = y[mask]\n\n            X_balanced, y_balanced = self._apply_sampling_strategy(\n                X_attr, y_attr, \n                balance_strategy,\n                sampling_params={'k_neighbors': 5 if balance_strategy == 'smote' else None}\n            )\n\n            eval_dataset = None\n            if validation_df is not None:\n                y_val = validation_df[attr]\n                val_mask = y_val.notna()\n                X_val_attr = X_val[val_mask]\n                y_val_attr = y_val[val_mask]\n                eval_dataset = Pool(X_val_attr, y_val_attr)\n\n            class_weights = self.calculate_class_weights(y_balanced, balance_strategy)\n\n            base_params = {\n                'iterations': epochs,\n                'verbose': 200,\n                'loss_function': 'MultiClass',\n                'eval_metric': 'MultiClass',\n                'custom_metric': ['F1'],\n                'early_stopping_rounds': 100,\n                'task_type': 'GPU',\n                'nan_mode': 'Min'\n            }\n\n            model_params = {**base_params, **model_params}\n            if class_weights is not None:\n                model_params['class_weights'] = class_weights\n\n            model = CatBoostClassifier(**model_params)\n\n            if eval_dataset:\n                model.fit(X_balanced, y_balanced, eval_set=eval_dataset)\n            else:\n                model.fit(X_balanced, y_balanced)\n\n            self.attribute_models[attr] = model\n            y_pred = model.predict(X_attr)\n            score = self.calculate_attribute_f1_score(y_attr, y_pred)\n\n            self.best_scores[attr] = score\n\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n            print(f\"Finished training {attr}. Best score: {score:.4f}\")\n        return self\n\n    def predict(self, df: pd.DataFrame) -> pd.DataFrame:\n        X = self.preprocess_features(df)\n        results = {attr: [] for attr in self.attributes}\n        \n        for attr in self.attributes:\n            if attr in self.attribute_models:\n                model = self.attribute_models[attr]\n                predictions = model.predict(X).flatten()\n                results[attr] = predictions.tolist()\n        \n        return pd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:41.588629Z","iopub.execute_input":"2024-11-25T22:31:41.588899Z","iopub.status.idle":"2024-11-25T22:31:41.612902Z","shell.execute_reply.started":"2024-11-25T22:31:41.588874Z","shell.execute_reply":"2024-11-25T22:31:41.611960Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Men_Tshirts_Model(BaseFashionModel):\n    def __init__(self):\n        \"\"\"\n        Initializes the Men T-shirts model with specific attribute configurations.\n        \"\"\"\n        super().__init__(num_attributes=5)\n        self.attr_configs = {\n            'attr_1': {\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.08\n                }\n            },\n            'attr_2': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1\n                }\n            },\n            'attr_3': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1\n                }\n            },\n            'attr_4': {\n                'balance_strategy': 'auto',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.09\n                }\n            },\n            'attr_5': {\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1\n                }\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:42.075487Z","iopub.execute_input":"2024-11-25T22:31:42.075887Z","iopub.status.idle":"2024-11-25T22:31:42.081976Z","shell.execute_reply.started":"2024-11-25T22:31:42.075833Z","shell.execute_reply":"2024-11-25T22:31:42.081093Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Sarees_Model(BaseFashionModel):\n    def __init__(self):\n        \"\"\"\n        Initializes the Sarees model with specific attribute configurations\n        and preprocessing steps.\n        \"\"\"\n        super().__init__(num_attributes=10)\n        self.attr_configs = {\n            'attr_1': {  \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 3,\n                    'min_data_in_leaf': 10,\n                    'random_strength': 1\n                }\n            },\n            'attr_2': {  \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'min_data_in_leaf': 15\n                }\n            },\n            'attr_3': {  \n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'min_data_in_leaf': 10\n                }\n            },\n            'attr_4': {  \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 9,\n                    'learning_rate': 0.03,\n                    'l2_leaf_reg': 7,\n                    'min_data_in_leaf': 20\n                }\n            },\n            'attr_5': { \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.04,\n                    'l2_leaf_reg': 5,\n                    'min_data_in_leaf': 15,\n                    'random_strength': 1\n                }\n            },\n            'attr_6': {  \n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'min_data_in_leaf': 10\n                }\n            },\n            'attr_7': {  \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'min_data_in_leaf': 15\n                }\n            },\n            'attr_8': {  \n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'min_data_in_leaf': 15\n                }\n            },\n            'attr_9': {  # print (9 classes)\n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 9,\n                    'learning_rate': 0.03,\n                    'l2_leaf_reg': 7,\n                    'min_data_in_leaf': 15,\n                    'random_strength': 1\n                }\n            },\n            'attr_10': {  \n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'min_data_in_leaf': 10\n                }\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:42.460684Z","iopub.execute_input":"2024-11-25T22:31:42.461445Z","iopub.status.idle":"2024-11-25T22:31:42.469072Z","shell.execute_reply.started":"2024-11-25T22:31:42.461411Z","shell.execute_reply":"2024-11-25T22:31:42.468219Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Kurtis_Model(BaseFashionModel):\n    def __init__(self):\n        \"\"\"\n        Initializes the Kurtis model with specific attribute configurations.\n        \"\"\"\n        super().__init__(num_attributes=9)\n        self.attr_configs = {\n            'attr_1': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 1\n                }\n            },\n            'attr_2': {  # Binary classification with imbalance\n                'balance_strategy': 'smote_tomek',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'random_strength': 0.8\n                }\n            },\n            'attr_3': {  # Binary classification with imbalance\n                'balance_strategy': 'smote_tomek',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'random_strength': 0.8\n                }\n            },\n            'attr_4': {  # More balanced binary classification\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 1\n                }\n            },\n            'attr_5': {  # Binary classification with imbalance\n                'balance_strategy': 'smote_tomek',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'random_strength': 0.8\n                }\n            },\n            'attr_6': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 1\n                }\n            },\n            'attr_7': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 1\n                }\n            },\n            'attr_8': {  # Sparse multi-class problem\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 7,\n                    'random_strength': 1.2,\n                    'min_data_in_leaf': 5\n                }\n            },\n            'attr_9': {  # Binary classification\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 1\n                }\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:42.885498Z","iopub.execute_input":"2024-11-25T22:31:42.885751Z","iopub.status.idle":"2024-11-25T22:31:42.893665Z","shell.execute_reply.started":"2024-11-25T22:31:42.885726Z","shell.execute_reply":"2024-11-25T22:31:42.892706Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Women_Tshirts_Model(BaseFashionModel):\n    def __init__(self):\n        \"\"\"\n        Initializes the Women T-shirts model with specific attribute configurations.\n        \"\"\"\n        super().__init__(num_attributes=8)\n        self.attr_configs = {\n            'attr_1': {  # 7-class problem with moderate confusion\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.07,\n                    'l2_leaf_reg': 4,\n                    'random_strength': 0.8,\n                    'bootstrap_type': 'Bernoulli',\n                    'subsample': 0.8\n                }\n            },\n            'attr_2': {  # 3-class problem with strong bias\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.05,\n                    'l2_leaf_reg': 5,\n                    'random_strength': 1.0,\n                    'bootstrap_type': 'Bernoulli',\n                    'subsample': 0.85\n                }\n            },\n            'attr_3': {  # Binary classification with class imbalance\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 0.5\n                }\n            },\n            'attr_4': {  # 3-class with strong performance\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 2,\n                    'random_strength': 0.3\n                }\n            },\n            'attr_5': {  # 6-class with moderate confusion\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 9,\n                    'learning_rate': 0.06,\n                    'l2_leaf_reg': 5,\n                    'random_strength': 1.2,\n                    'bootstrap_type': 'Bernoulli',\n                    'subsample': 0.75\n                }\n            },\n            'attr_6': {  # 3-class with strong class 2\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 3,\n                    'random_strength': 0.7\n                }\n            },\n            'attr_7': {  # Binary classification with good separation\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 2,\n                    'random_strength': 0.5\n                }\n            },\n            'attr_8': {  # Binary classification with strong separation\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 5,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 2,\n                    'random_strength': 0.3\n                }\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:43.307391Z","iopub.execute_input":"2024-11-25T22:31:43.308206Z","iopub.status.idle":"2024-11-25T22:31:43.315416Z","shell.execute_reply.started":"2024-11-25T22:31:43.308169Z","shell.execute_reply":"2024-11-25T22:31:43.314644Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Women_Tops_Model(BaseFashionModel):\n    def __init__(self):\n        \"\"\"\n        Initializes the Women Tops & Tunics model with specific attribute configurations.\n        \"\"\"\n        super().__init__(num_attributes=10)\n        self.attr_configs = {\n            'attr_1': {\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.08,\n                    'l2_leaf_reg': 5\n                }\n            },\n            'attr_2': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.09,\n                    'l2_leaf_reg': 3\n                }\n            },\n            'attr_3': {\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 6,\n                    'learning_rate': 0.1,\n                    'l2_leaf_reg': 4  \n                }\n            },\n            'attr_4': {\n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 9,\n                    'learning_rate': 0.07,\n                    'random_strength': 1\n                }\n            },\n            'attr_5': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.085,\n                    'random_strength': 0.8\n                }\n            },\n            'attr_6': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.09,\n                    'l2_leaf_reg': 4\n                }\n            },\n            'attr_7': {\n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.075,\n                    'random_strength': 1.2\n                }\n            },\n            'attr_8': {\n                'balance_strategy': 'smote',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.085,\n                    'l2_leaf_reg': 3\n                }\n            },\n            'attr_9': {\n                'balance_strategy': 'class_weight',\n                'model_params': {\n                    'depth': 8,\n                    'learning_rate': 0.08,\n                    'random_strength': 0.9\n                }\n            },\n            'attr_10': {\n                'balance_strategy': 'hybrid',\n                'model_params': {\n                    'depth': 7,\n                    'learning_rate': 0.09,\n                    'l2_leaf_reg': 4\n                }\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:43.740871Z","iopub.execute_input":"2024-11-25T22:31:43.741151Z","iopub.status.idle":"2024-11-25T22:31:43.748166Z","shell.execute_reply.started":"2024-11-25T22:31:43.741124Z","shell.execute_reply":"2024-11-25T22:31:43.747380Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class UnifiedFashionModelPipeline:\n    def __init__(self):\n        \"\"\"\n        Initialize the pipeline with category-specific models.\n        \"\"\"\n        self.models = {\n            'Men Tshirts': Men_Tshirts_Model(),\n            'Sarees': Sarees_Model(), \n            'Kurtis': Kurtis_Model(),\n            'Women Tshirts': Women_Tshirts_Model(),\n            'Women Tops & Tunics': Women_Tops_Model()\n        }\n        self.label_encoders = {}\n\n    def preprocess_data(self, df: pd.DataFrame, category: str, num_attributes: int) -> pd.DataFrame:\n        \"\"\"\n        Preprocess data for a specific category, including label encoding.\n\n        Parameters:\n        - df: Input dataframe.\n        - category: Category of the fashion item.\n        - num_attributes: Number of attributes for the category.\n\n        Returns:\n        - Preprocessed dataframe with encoded labels.\n        \"\"\"\n        label_encoders = {}\n        for i in range(1, num_attributes + 1):\n            attr = f'attr_{i}'\n            le = LabelEncoder()\n            df[attr] = le.fit_transform(df[attr])\n            label_encoders[attr] = le\n        self.label_encoders[category] = label_encoders\n        return df\n\n    def train_model(self, category: str, train_data: pd.DataFrame, val_data: pd.DataFrame, epochs: int = 2000):\n        \"\"\"\n        Train the model for a specific category.\n\n        Parameters:\n        - category: Category of the fashion item.\n        - train_data: Training dataset.\n        - val_data: Validation dataset.\n        - epochs: Number of epochs to train the model.\n        \"\"\"\n        model = self.models[category]\n        print(f\"Training model for category: {category}\")\n        model.train(train_data, val_data, epochs)\n        \n        torch.cuda.empty_cache()\n        gc.collect()\n        print(f\"Finished training model for {category}\")\n        print()\n\n    def predict(self, test_data: pd.DataFrame, category: str) -> pd.DataFrame:\n        \"\"\"\n        Predict attributes for a specific category.\n\n        Parameters:\n        - test_data: Test dataset containing the features.\n        - category: Category of the fashion item.\n\n        Returns:\n        - DataFrame with predictions (decoded labels).\n        \"\"\"\n        model = self.models[category]\n        print(f\"Predicting for category: {category}\")\n        predictions = model.predict(test_data)\n        label_encoders = self.label_encoders[category]\n        for col in predictions.columns:\n            predictions[col] = label_encoders[col].inverse_transform(predictions[col])\n        return predictions\n\n    def fill_predictions(self, test_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Fill predictions in the test dataframe using model predictions.\n\n        Parameters:\n        - test_df: Test dataframe\n\n        Returns:\n        - Test dataframe with predictions filled.\n        \"\"\"\n        result_df = test_df.copy()\n        for category, model in self.models.items():\n            category_data = test_df[test_df['Category'] == category]\n            if not category_data.empty:\n                predictions = self.predict(category_data, category)\n                predictions = predictions.set_index(category_data.index)\n                result_df.update(predictions)\n        return result_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:44.346090Z","iopub.execute_input":"2024-11-25T22:31:44.346374Z","iopub.status.idle":"2024-11-25T22:31:44.356227Z","shell.execute_reply.started":"2024-11-25T22:31:44.346341Z","shell.execute_reply":"2024-11-25T22:31:44.355269Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_images = '/kaggle/input/visual-taxonomy/train_images'\ndata = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')  \ndata['image_path'] = data['id'].apply(lambda x: os.path.join(train_images, f\"{str(x).zfill(6)}.jpg\"))\ndata = data.drop(['id'], axis=1)\n\nfeature_extractor = UnifiedFeatureExtractor()\nmodel_names = ['resnet', 'efficientnet', 'convnext']\n\ndatasets = {\n    'Men_Tshirts': data[data['Category'] == 'Men Tshirts'].reset_index(drop=True),\n    'Sarees': data[data['Category'] == 'Sarees'].reset_index(drop=True),\n    'Kurtis': data[data['Category'] == 'Kurtis'].reset_index(drop=True),\n    'Women_Tshirts': data[data['Category'] == 'Women Tshirts'].reset_index(drop=True),\n    'Womens_Tops': data[data['Category'] == 'Women Tops & Tunics'].reset_index(drop=True)\n}\n\nfor model_name in model_names:\n    for dataset_name, dataset_df in datasets.items():\n        print(f\"Processing {dataset_name} with {model_name}...\")\n        processed_df = feature_extractor.extract_features(dataset_df.copy(), [model_name])\n        datasets[dataset_name] = processed_df\n        torch.cuda.empty_cache()\n        gc.collect()\n\nimputer = UnifiedImputer()\nfor dataset_name, dataset_df in datasets.items():\n    print(f\"Imputing {dataset_name}...\")\n    datasets[dataset_name] = imputer.impute_attributes(dataset_df.copy(), n_attributes=10)\n    gc.collect()\n\ntrain_df = pd.concat(datasets.values(), ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:51:35.510685Z","iopub.execute_input":"2024-11-25T23:51:35.511500Z","iopub.status.idle":"2024-11-25T23:51:35.554177Z","shell.execute_reply.started":"2024-11-25T23:51:35.511453Z","shell.execute_reply":"2024-11-25T23:51:35.553240Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                  Category  len      attr_1   attr_2   attr_3       attr_4  \\\n0              Men Tshirts    5     default    round  printed      default   \n1              Men Tshirts    5  multicolor     polo    solid        solid   \n2              Men Tshirts    5     default     polo    solid        solid   \n3              Men Tshirts    5  multicolor     polo    solid        solid   \n4              Men Tshirts    5  multicolor     polo    solid        solid   \n...                    ...  ...         ...      ...      ...          ...   \n70208  Women Tops & Tunics   10  multicolor   fitted  regular  square neck   \n70209  Women Tops & Tunics   10      yellow  regular     crop   round neck   \n70210  Women Tops & Tunics   10      maroon   fitted     crop   round neck   \n70211  Women Tops & Tunics   10       black  regular  regular         high   \n70212  Women Tops & Tunics   10        pink     boxy     crop       v-neck   \n\n              attr_5   attr_6      attr_7         attr_8           attr_9  \\\n0      short sleeves      NaN         NaN            NaN              NaN   \n1      short sleeves      NaN         NaN            NaN              NaN   \n2      short sleeves      NaN         NaN            NaN              NaN   \n3      short sleeves      NaN         NaN            NaN              NaN   \n4      short sleeves      NaN         NaN            NaN              NaN   \n...              ...      ...         ...            ...              ...   \n70208         casual  printed     default  short sleeves  regular sleeves   \n70209         casual  default     default  short sleeves  regular sleeves   \n70210         casual    solid       solid  short sleeves  regular sleeves   \n70211         casual    solid       solid  short sleeves  regular sleeves   \n70212         casual  printed  typography  short sleeves  regular sleeves   \n\n             attr_10                                         image_path  \\\n0                NaN  /kaggle/input/visual-taxonomy/train_images/000...   \n1                NaN  /kaggle/input/visual-taxonomy/train_images/000...   \n2                NaN  /kaggle/input/visual-taxonomy/train_images/000...   \n3                NaN  /kaggle/input/visual-taxonomy/train_images/000...   \n4                NaN  /kaggle/input/visual-taxonomy/train_images/000...   \n...              ...                                                ...   \n70208        ruffles  /kaggle/input/visual-taxonomy/train_images/070...   \n70209        knitted  /kaggle/input/visual-taxonomy/train_images/070...   \n70210        knitted  /kaggle/input/visual-taxonomy/train_images/070...   \n70211        ruffles  /kaggle/input/visual-taxonomy/train_images/070...   \n70212  waist tie-ups  /kaggle/input/visual-taxonomy/train_images/070...   \n\n                                   image_features_resnet  \\\n0      [0.0, 0.14449768, 0.16205992, 0.012917416, 0.0...   \n1      [0.0, 0.051582135, 0.07612845, 0.0, 0.0, 0.008...   \n2      [0.0, 0.1814174, 0.048469067, 0.0, 0.0, 0.0, 0...   \n3      [0.0, 0.18438621, 0.0016736547, 0.0, 0.0, 0.08...   \n4      [0.0, 0.24398537, 0.17563587, 0.0, 0.0, 0.0075...   \n...                                                  ...   \n70208  [0.39907238, 0.0, 0.5148285, 0.0, 0.0, 0.04164...   \n70209  [0.0, 0.26035887, 0.0, 0.0, 0.0, 0.080200195, ...   \n70210  [0.0, 0.0, 0.03390736, 0.0, 0.0028240923, 0.02...   \n70211  [0.30429938, 0.0, 0.39254114, 0.0, 0.0, 0.0, 0...   \n70212  [0.24637356, 0.0, 0.0, 0.08191846, 0.030835241...   \n\n                                   image_features_effnet  \\\n0      [0.2860457, -0.050842, -0.1223934, -0.10037970...   \n1      [-0.18414812, -0.1390237, -0.11305254, -0.0527...   \n2      [0.0041561127, -0.13763672, -0.11459265, -0.08...   \n3      [-0.13240191, -0.17773184, -0.10929884, -0.072...   \n4      [-0.15026966, -0.13859507, -0.117739886, -0.07...   \n...                                                  ...   \n70208  [-0.16685976, 0.19534639, -0.07173743, 0.06004...   \n70209  [0.1728438, -0.019694783, -0.07842853, -0.0938...   \n70210  [-0.1257465, -0.11419905, -0.105264194, -0.110...   \n70211  [-0.16440184, -0.14141025, -0.1457725, 0.66374...   \n70212  [-0.17696261, -0.12520817, -0.09639064, -0.065...   \n\n                                 image_features_convnext  \n0      [0.27109453, -0.12416643, 0.94380677, -0.18601...  \n1      [-0.38173568, 0.12800789, 0.40220565, 0.866345...  \n2      [-0.35483563, 0.30252552, 0.4228179, 0.8531302...  \n3      [-0.22742647, 0.27420285, 0.46182054, 0.543102...  \n4      [-0.31193736, 0.17937586, 0.3859397, 0.7873238...  \n...                                                  ...  \n70208  [-0.29303807, -0.022686705, -0.52767247, -0.27...  \n70209  [-0.119377755, 0.3176656, 0.60180813, 0.915949...  \n70210  [-0.284321, 0.1881754, 0.6135644, -0.57130915,...  \n70211  [-0.0926386, -0.25483623, 0.8241464, 0.1286146...  \n70212  [0.007528356, 0.110894434, 1.2352048, -0.23887...  \n\n[70213 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n      <th>image_path</th>\n      <th>image_features_resnet</th>\n      <th>image_features_effnet</th>\n      <th>image_features_convnext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>[0.0, 0.14449768, 0.16205992, 0.012917416, 0.0...</td>\n      <td>[0.2860457, -0.050842, -0.1223934, -0.10037970...</td>\n      <td>[0.27109453, -0.12416643, 0.94380677, -0.18601...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>[0.0, 0.051582135, 0.07612845, 0.0, 0.0, 0.008...</td>\n      <td>[-0.18414812, -0.1390237, -0.11305254, -0.0527...</td>\n      <td>[-0.38173568, 0.12800789, 0.40220565, 0.866345...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>[0.0, 0.1814174, 0.048469067, 0.0, 0.0, 0.0, 0...</td>\n      <td>[0.0041561127, -0.13763672, -0.11459265, -0.08...</td>\n      <td>[-0.35483563, 0.30252552, 0.4228179, 0.8531302...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>[0.0, 0.18438621, 0.0016736547, 0.0, 0.0, 0.08...</td>\n      <td>[-0.13240191, -0.17773184, -0.10929884, -0.072...</td>\n      <td>[-0.22742647, 0.27420285, 0.46182054, 0.543102...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>[0.0, 0.24398537, 0.17563587, 0.0, 0.0, 0.0075...</td>\n      <td>[-0.15026966, -0.13859507, -0.117739886, -0.07...</td>\n      <td>[-0.31193736, 0.17937586, 0.3859397, 0.7873238...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70208</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>fitted</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n      <td>[0.39907238, 0.0, 0.5148285, 0.0, 0.0, 0.04164...</td>\n      <td>[-0.16685976, 0.19534639, -0.07173743, 0.06004...</td>\n      <td>[-0.29303807, -0.022686705, -0.52767247, -0.27...</td>\n    </tr>\n    <tr>\n      <th>70209</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>yellow</td>\n      <td>regular</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>default</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n      <td>[0.0, 0.26035887, 0.0, 0.0, 0.0, 0.080200195, ...</td>\n      <td>[0.1728438, -0.019694783, -0.07842853, -0.0938...</td>\n      <td>[-0.119377755, 0.3176656, 0.60180813, 0.915949...</td>\n    </tr>\n    <tr>\n      <th>70210</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>maroon</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n      <td>[0.0, 0.0, 0.03390736, 0.0, 0.0028240923, 0.02...</td>\n      <td>[-0.1257465, -0.11419905, -0.105264194, -0.110...</td>\n      <td>[-0.284321, 0.1881754, 0.6135644, -0.57130915,...</td>\n    </tr>\n    <tr>\n      <th>70211</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>black</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>high</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n      <td>[0.30429938, 0.0, 0.39254114, 0.0, 0.0, 0.0, 0...</td>\n      <td>[-0.16440184, -0.14141025, -0.1457725, 0.66374...</td>\n      <td>[-0.0926386, -0.25483623, 0.8241464, 0.1286146...</td>\n    </tr>\n    <tr>\n      <th>70212</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>v-neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>waist tie-ups</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n      <td>[0.24637356, 0.0, 0.0, 0.08191846, 0.030835241...</td>\n      <td>[-0.17696261, -0.12520817, -0.09639064, -0.065...</td>\n      <td>[0.007528356, 0.110894434, 1.2352048, -0.23887...</td>\n    </tr>\n  </tbody>\n</table>\n<p>70213 rows  16 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"pipeline = UnifiedFashionModelPipeline()\nfor category, model in pipeline.models.items():\n    category_data = train_df[train_df['Category'] == category].copy()\n    num_attributes = len(model.attributes)\n    \n    valid_columns = {f\"attr_{i}\" for i in range(1, num_attributes + 1)}\n    columns_to_keep = [col for col in category_data.columns if not col.startswith(\"attr_\") or col in valid_columns]\n    category_data = category_data[columns_to_keep]\n    category_data = category_data.dropna()\n    category_data = pipeline.preprocess_data(category_data, category, num_attributes)\n    \n    train_data, val_data = train_test_split(category_data, test_size=0.2, random_state=42)\n    \n    pipeline.train_model(category, train_data, val_data)\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T22:31:58.059202Z","iopub.execute_input":"2024-11-25T22:31:58.059946Z","iopub.status.idle":"2024-11-25T23:51:35.508894Z","shell.execute_reply.started":"2024-11-25T22:31:58.059903Z","shell.execute_reply":"2024-11-25T23:51:35.508004Z"}},"outputs":[{"name":"stdout","text":"Training model for category: Men Tshirts\nPreparing data for training...\nTraining models for each attribute...\n\nTraining model for attr_1\n0:\tlearn: 1.3060559\ttest: 1.3166457\tbest: 1.3166457 (0)\ttotal: 12.5s\tremaining: 6h 55m 35s\n200:\tlearn: 0.2957116\ttest: 0.6531640\tbest: 0.6531640 (200)\ttotal: 37.8s\tremaining: 5m 38s\n400:\tlearn: 0.2058022\ttest: 0.6410570\tbest: 0.6402187 (385)\ttotal: 1m\tremaining: 4m\nbestTest = 0.6402186741\nbestIteration = 385\nShrink model to first 386 iterations.\nFinished training attr_1. Best score: 0.9526\n\nTraining model for attr_2\n0:\tlearn: 0.6083637\ttest: 0.6088103\tbest: 0.6088103 (0)\ttotal: 220ms\tremaining: 7m 18s\n200:\tlearn: 0.0134421\ttest: 0.0399376\tbest: 0.0399376 (200)\ttotal: 4.57s\tremaining: 40.9s\n400:\tlearn: 0.0069285\ttest: 0.0376417\tbest: 0.0376223 (399)\ttotal: 8.87s\tremaining: 35.4s\n600:\tlearn: 0.0048327\ttest: 0.0371646\tbest: 0.0369658 (593)\ttotal: 13.1s\tremaining: 30.4s\n800:\tlearn: 0.0037987\ttest: 0.0367456\tbest: 0.0366466 (782)\ttotal: 17.2s\tremaining: 25.7s\nbestTest = 0.03664661017\nbestIteration = 782\nShrink model to first 783 iterations.\nFinished training attr_2. Best score: 0.9995\n\nTraining model for attr_3\n0:\tlearn: 0.6147942\ttest: 0.6165043\tbest: 0.6165043 (0)\ttotal: 36ms\tremaining: 1m 11s\n200:\tlearn: 0.0385425\ttest: 0.1015411\tbest: 0.1015024 (199)\ttotal: 4.35s\tremaining: 39s\n400:\tlearn: 0.0226707\ttest: 0.1001205\tbest: 0.0997680 (355)\ttotal: 8.6s\tremaining: 34.3s\nbestTest = 0.09942724454\nbestIteration = 419\nShrink model to first 420 iterations.\nFinished training attr_3. Best score: 0.9988\n\nTraining model for attr_4\n0:\tlearn: 0.9928119\ttest: 0.9949514\tbest: 0.9949514 (0)\ttotal: 1.81s\tremaining: 1h 22s\n200:\tlearn: 0.1321450\ttest: 0.2859986\tbest: 0.2859437 (199)\ttotal: 13.1s\tremaining: 1m 57s\n400:\tlearn: 0.0907910\ttest: 0.2836596\tbest: 0.2829237 (380)\ttotal: 23.6s\tremaining: 1m 33s\nbestTest = 0.2829236789\nbestIteration = 380\nShrink model to first 381 iterations.\nFinished training attr_4. Best score: 0.9796\n\nTraining model for attr_5\n0:\tlearn: 0.6066389\ttest: 0.6104993\tbest: 0.6104993 (0)\ttotal: 38ms\tremaining: 1m 15s\n200:\tlearn: 0.0083157\ttest: 0.0479658\tbest: 0.0479658 (200)\ttotal: 4.48s\tremaining: 40.1s\nbestTest = 0.04767683049\nbestIteration = 208\nShrink model to first 209 iterations.\nFinished training attr_5. Best score: 0.9972\nFinished training model for Men Tshirts\n\nTraining model for category: Sarees\nPreparing data for training...\nTraining models for each attribute...\n\nTraining model for attr_1\n0:\tlearn: 1.2802499\ttest: 1.2854438\tbest: 1.2854438 (0)\ttotal: 155ms\tremaining: 5m 10s\n200:\tlearn: 0.2604160\ttest: 0.3250595\tbest: 0.3250595 (200)\ttotal: 24.1s\tremaining: 3m 35s\n400:\tlearn: 0.2347392\ttest: 0.3203804\tbest: 0.3201819 (386)\ttotal: 46.3s\tremaining: 3m 4s\nbestTest = 0.3201819139\nbestIteration = 386\nShrink model to first 387 iterations.\nFinished training attr_1. Best score: 0.8230\n\nTraining model for attr_2\n0:\tlearn: 1.6867582\ttest: 1.6902124\tbest: 1.6902124 (0)\ttotal: 228ms\tremaining: 7m 36s\n200:\tlearn: 0.6537123\ttest: 0.7155293\tbest: 0.7155293 (200)\ttotal: 34s\tremaining: 5m 4s\n400:\tlearn: 0.6096118\ttest: 0.7106594\tbest: 0.7105242 (379)\ttotal: 1m 5s\tremaining: 4m 22s\n600:\tlearn: 0.5795849\ttest: 0.7117648\tbest: 0.7102379 (527)\ttotal: 1m 37s\tremaining: 3m 47s\nbestTest = 0.7102379197\nbestIteration = 527\nShrink model to first 528 iterations.\nFinished training attr_2. Best score: 0.7255\n\nTraining model for attr_3\n0:\tlearn: 0.9806590\ttest: 0.9888339\tbest: 0.9888339 (0)\ttotal: 90.1ms\tremaining: 3m\n200:\tlearn: 0.1707760\ttest: 0.2609284\tbest: 0.2609284 (200)\ttotal: 12.2s\tremaining: 1m 49s\n400:\tlearn: 0.1474316\ttest: 0.2583463\tbest: 0.2577454 (361)\ttotal: 23.6s\tremaining: 1m 33s\nbestTest = 0.257014836\nbestIteration = 486\nShrink model to first 487 iterations.\nFinished training attr_3. Best score: 0.9334\n\nTraining model for attr_4\n0:\tlearn: 2.0154824\ttest: 2.0205896\tbest: 2.0205896 (0)\ttotal: 423ms\tremaining: 14m 4s\n200:\tlearn: 0.8730821\ttest: 0.9508203\tbest: 0.9508203 (200)\ttotal: 1m 20s\tremaining: 12m 3s\n400:\tlearn: 0.8250595\ttest: 0.9334024\tbest: 0.9334024 (400)\ttotal: 2m 35s\tremaining: 10m 18s\n600:\tlearn: 0.7928102\ttest: 0.9272274\tbest: 0.9272274 (600)\ttotal: 3m 49s\tremaining: 8m 53s\n800:\tlearn: 0.7662341\ttest: 0.9245179\tbest: 0.9244640 (795)\ttotal: 5m 4s\tremaining: 7m 35s\n1000:\tlearn: 0.7434367\ttest: 0.9240253\tbest: 0.9240206 (989)\ttotal: 6m 20s\tremaining: 6m 19s\n1200:\tlearn: 0.7241285\ttest: 0.9239980\tbest: 0.9236284 (1125)\ttotal: 7m 36s\tremaining: 5m 3s\nbestTest = 0.9236284291\nbestIteration = 1125\nShrink model to first 1126 iterations.\nFinished training attr_4. Best score: 0.6401\n\nTraining model for attr_5\n0:\tlearn: 1.3373164\ttest: 1.3400119\tbest: 1.3400119 (0)\ttotal: 157ms\tremaining: 5m 14s\n200:\tlearn: 0.6736395\ttest: 0.7230845\tbest: 0.7230824 (198)\ttotal: 24.3s\tremaining: 3m 37s\n400:\tlearn: 0.6423579\ttest: 0.7173884\tbest: 0.7173749 (399)\ttotal: 47.2s\tremaining: 3m 8s\n600:\tlearn: 0.6190715\ttest: 0.7162202\tbest: 0.7161780 (598)\ttotal: 1m 10s\tremaining: 2m 43s\nbestTest = 0.7160733421\nbestIteration = 644\nShrink model to first 645 iterations.\nFinished training attr_5. Best score: 0.6538\n\nTraining model for attr_6\n0:\tlearn: 0.9805791\ttest: 0.9896686\tbest: 0.9896686 (0)\ttotal: 89.4ms\tremaining: 2m 58s\n200:\tlearn: 0.1164709\ttest: 0.1994781\tbest: 0.1987767 (185)\ttotal: 12.6s\tremaining: 1m 52s\n400:\tlearn: 0.0951620\ttest: 0.2030807\tbest: 0.1974931 (310)\ttotal: 24.1s\tremaining: 1m 36s\nbestTest = 0.1974931073\nbestIteration = 310\nShrink model to first 311 iterations.\nFinished training attr_6. Best score: 0.9353\n\nTraining model for attr_7\n0:\tlearn: 1.2972124\ttest: 1.3044468\tbest: 1.3044468 (0)\ttotal: 154ms\tremaining: 5m 7s\n200:\tlearn: 0.4123819\ttest: 0.4823456\tbest: 0.4823456 (200)\ttotal: 23.9s\tremaining: 3m 33s\n400:\tlearn: 0.3852128\ttest: 0.4789013\tbest: 0.4786385 (361)\ttotal: 46.2s\tremaining: 3m 4s\nbestTest = 0.4786385096\nbestIteration = 361\nShrink model to first 362 iterations.\nFinished training attr_7. Best score: 0.7810\n\nTraining model for attr_8\n0:\tlearn: 1.4714387\ttest: 1.4757248\tbest: 1.4757248 (0)\ttotal: 183ms\tremaining: 6m 5s\n200:\tlearn: 0.3220198\ttest: 0.3683590\tbest: 0.3683590 (200)\ttotal: 29.1s\tremaining: 4m 20s\n400:\tlearn: 0.3008697\ttest: 0.3645794\tbest: 0.3644314 (390)\ttotal: 56.3s\tremaining: 3m 44s\n600:\tlearn: 0.2871774\ttest: 0.3649982\tbest: 0.3640576 (527)\ttotal: 1m 23s\tremaining: 3m 13s\nbestTest = 0.3640576077\nbestIteration = 527\nShrink model to first 528 iterations.\nFinished training attr_8. Best score: 0.7244\n\nTraining model for attr_9\n0:\tlearn: 2.1025355\ttest: 2.1035212\tbest: 2.1035212 (0)\ttotal: 530ms\tremaining: 17m 38s\n200:\tlearn: 0.7591377\ttest: 0.8337009\tbest: 0.8337009 (200)\ttotal: 1m 30s\tremaining: 13m 27s\n400:\tlearn: 0.7017173\ttest: 0.8125700\tbest: 0.8125700 (400)\ttotal: 2m 52s\tremaining: 11m 27s\n600:\tlearn: 0.6651402\ttest: 0.8060298\tbest: 0.8060298 (600)\ttotal: 4m 15s\tremaining: 9m 55s\n800:\tlearn: 0.6368300\ttest: 0.8028594\tbest: 0.8028594 (800)\ttotal: 5m 38s\tremaining: 8m 27s\n1000:\tlearn: 0.6129694\ttest: 0.8022385\tbest: 0.8022275 (988)\ttotal: 7m 2s\tremaining: 7m 1s\n1200:\tlearn: 0.5927116\ttest: 0.8015727\tbest: 0.8014101 (1190)\ttotal: 8m 25s\tremaining: 5m 36s\nbestTest = 0.8013513638\nbestIteration = 1223\nShrink model to first 1224 iterations.\nFinished training attr_9. Best score: 0.7053\n\nTraining model for attr_10\n0:\tlearn: 0.6704386\ttest: 0.6716963\tbest: 0.6716963 (0)\ttotal: 58.6ms\tremaining: 1m 57s\n200:\tlearn: 0.4008160\ttest: 0.4322329\tbest: 0.4320419 (198)\ttotal: 8.23s\tremaining: 1m 13s\n400:\tlearn: 0.3442991\ttest: 0.4086060\tbest: 0.4083750 (398)\ttotal: 16.4s\tremaining: 1m 5s\n600:\tlearn: 0.3054453\ttest: 0.4025872\tbest: 0.4024335 (599)\ttotal: 24.6s\tremaining: 57.3s\nbestTest = 0.4020916025\nbestIteration = 624\nShrink model to first 625 iterations.\nFinished training attr_10. Best score: 0.8119\nFinished training model for Sarees\n\nTraining model for category: Kurtis\nPreparing data for training...\nTraining models for each attribute...\n\nTraining model for attr_1\n0:\tlearn: 2.4129192\ttest: 2.4621644\tbest: 2.4621644 (0)\ttotal: 925ms\tremaining: 30m 48s\n200:\tlearn: 0.3073219\ttest: 1.0834981\tbest: 1.0834981 (200)\ttotal: 38.8s\tremaining: 5m 47s\n400:\tlearn: 0.1944346\ttest: 1.0607564\tbest: 1.0591875 (378)\ttotal: 1m 12s\tremaining: 4m 50s\n600:\tlearn: 0.1460372\ttest: 1.0495645\tbest: 1.0491572 (597)\ttotal: 1m 46s\tremaining: 4m 6s\nbestTest = 1.047312829\nbestIteration = 614\nShrink model to first 615 iterations.\nFinished training attr_1. Best score: 0.9619\n\nTraining model for attr_2\n0:\tlearn: 0.6702922\ttest: 0.6716796\tbest: 0.6716796 (0)\ttotal: 39.4ms\tremaining: 1m 18s\n200:\tlearn: 0.1418929\ttest: 0.3136576\tbest: 0.3136576 (200)\ttotal: 5.09s\tremaining: 45.6s\n400:\tlearn: 0.1034135\ttest: 0.3077682\tbest: 0.3073709 (368)\ttotal: 9.58s\tremaining: 38.2s\n600:\tlearn: 0.0869354\ttest: 0.3065525\tbest: 0.3050587 (568)\ttotal: 14s\tremaining: 32.5s\nbestTest = 0.3043140333\nbestIteration = 670\nShrink model to first 671 iterations.\nFinished training attr_2. Best score: 0.9402\n\nTraining model for attr_3\n0:\tlearn: 0.6727206\ttest: 0.6733008\tbest: 0.6733008 (0)\ttotal: 36.9ms\tremaining: 1m 13s\n200:\tlearn: 0.2081783\ttest: 0.4394045\tbest: 0.4375265 (159)\ttotal: 4.99s\tremaining: 44.6s\nbestTest = 0.4375264679\nbestIteration = 159\nShrink model to first 160 iterations.\nFinished training attr_3. Best score: 0.8784\n\nTraining model for attr_4\n0:\tlearn: 0.6585051\ttest: 0.6666290\tbest: 0.6666290 (0)\ttotal: 37.5ms\tremaining: 1m 15s\nbestTest = 0.4323350441\nbestIteration = 53\nShrink model to first 54 iterations.\nFinished training attr_4. Best score: 0.9153\n\nTraining model for attr_5\n0:\tlearn: 0.6603778\ttest: 0.6626845\tbest: 0.6626845 (0)\ttotal: 38.5ms\tremaining: 1m 16s\n200:\tlearn: 0.0669771\ttest: 0.1582986\tbest: 0.1579077 (198)\ttotal: 4.95s\tremaining: 44.3s\n400:\tlearn: 0.0462911\ttest: 0.1476871\tbest: 0.1476871 (400)\ttotal: 9.27s\tremaining: 37s\n600:\tlearn: 0.0371626\ttest: 0.1433737\tbest: 0.1431406 (594)\ttotal: 13.5s\tremaining: 31.5s\n800:\tlearn: 0.0316842\ttest: 0.1402246\tbest: 0.1400254 (783)\ttotal: 17.8s\tremaining: 26.6s\n1000:\tlearn: 0.0279241\ttest: 0.1382076\tbest: 0.1379845 (969)\ttotal: 22.1s\tremaining: 22s\n1200:\tlearn: 0.0250491\ttest: 0.1361462\tbest: 0.1357927 (1183)\ttotal: 26.3s\tremaining: 17.5s\n1400:\tlearn: 0.0226929\ttest: 0.1348455\tbest: 0.1348455 (1400)\ttotal: 30.5s\tremaining: 13.1s\nbestTest = 0.1347468468\nbestIteration = 1429\nShrink model to first 1430 iterations.\nFinished training attr_5. Best score: 0.9846\n\nTraining model for attr_6\n0:\tlearn: 0.6535859\ttest: 0.6573564\tbest: 0.6573564 (0)\ttotal: 55.7ms\tremaining: 1m 51s\n200:\tlearn: 0.1291266\ttest: 0.2499731\tbest: 0.2496796 (179)\ttotal: 7.85s\tremaining: 1m 10s\nbestTest = 0.2493513185\nbestIteration = 216\nShrink model to first 217 iterations.\nFinished training attr_6. Best score: 0.9554\n\nTraining model for attr_7\n0:\tlearn: 0.6550133\ttest: 0.6576660\tbest: 0.6576660 (0)\ttotal: 54.6ms\tremaining: 1m 49s\n200:\tlearn: 0.1311254\ttest: 0.2526958\tbest: 0.2526958 (200)\ttotal: 7.8s\tremaining: 1m 9s\nbestTest = 0.2522968195\nbestIteration = 215\nShrink model to first 216 iterations.\nFinished training attr_7. Best score: 0.9584\n\nTraining model for attr_8\n0:\tlearn: 1.0306855\ttest: 1.0418250\tbest: 1.0418250 (0)\ttotal: 134ms\tremaining: 4m 28s\n200:\tlearn: 0.0521391\ttest: 0.1262691\tbest: 0.1262691 (200)\ttotal: 21.8s\tremaining: 3m 15s\n400:\tlearn: 0.0332368\ttest: 0.1070831\tbest: 0.1070000 (399)\ttotal: 39.8s\tremaining: 2m 38s\n600:\tlearn: 0.0261511\ttest: 0.1000500\tbest: 0.1000500 (600)\ttotal: 57.4s\tremaining: 2m 13s\n800:\tlearn: 0.0221003\ttest: 0.0958937\tbest: 0.0958937 (800)\ttotal: 1m 14s\tremaining: 1m 52s\n1000:\tlearn: 0.0192334\ttest: 0.0933818\tbest: 0.0933818 (1000)\ttotal: 1m 32s\tremaining: 1m 32s\n1200:\tlearn: 0.0170626\ttest: 0.0913028\tbest: 0.0913028 (1200)\ttotal: 1m 49s\tremaining: 1m 13s\n1400:\tlearn: 0.0152238\ttest: 0.0895893\tbest: 0.0895893 (1400)\ttotal: 2m 7s\tremaining: 54.4s\n1600:\tlearn: 0.0137796\ttest: 0.0882804\tbest: 0.0882608 (1588)\ttotal: 2m 24s\tremaining: 36.1s\n1800:\tlearn: 0.0126240\ttest: 0.0871725\tbest: 0.0871421 (1797)\ttotal: 2m 42s\tremaining: 17.9s\n1999:\tlearn: 0.0117139\ttest: 0.0865134\tbest: 0.0865125 (1987)\ttotal: 2m 59s\tremaining: 0us\nbestTest = 0.08651250686\nbestIteration = 1987\nShrink model to first 1988 iterations.\nFinished training attr_8. Best score: 0.9971\n\nTraining model for attr_9\n0:\tlearn: 0.6065350\ttest: 0.6111829\tbest: 0.6111829 (0)\ttotal: 36.8ms\tremaining: 1m 13s\n200:\tlearn: 0.0043663\ttest: 0.0359501\tbest: 0.0359501 (200)\ttotal: 4.58s\tremaining: 41s\n400:\tlearn: 0.0022037\ttest: 0.0330244\tbest: 0.0323545 (384)\ttotal: 8.86s\tremaining: 35.3s\n600:\tlearn: 0.0013647\ttest: 0.0307317\tbest: 0.0305758 (597)\ttotal: 13.1s\tremaining: 30.6s\n800:\tlearn: 0.0009120\ttest: 0.0298290\tbest: 0.0292981 (707)\ttotal: 17.5s\tremaining: 26.2s\nbestTest = 0.02929814039\nbestIteration = 707\nShrink model to first 708 iterations.\nFinished training attr_9. Best score: 1.0000\nFinished training model for Kurtis\n\nTraining model for category: Women Tshirts\nPreparing data for training...\nTraining models for each attribute...\n\nTraining model for attr_1\n0:\tlearn: 1.8314710\ttest: 1.8439571\tbest: 1.8439571 (0)\ttotal: 3.53s\tremaining: 1h 57m 41s\n200:\tlearn: 0.3023060\ttest: 0.7193160\tbest: 0.7192156 (199)\ttotal: 45.7s\tremaining: 6m 49s\n400:\tlearn: 0.2115949\ttest: 0.7009010\tbest: 0.7009010 (400)\ttotal: 1m 21s\tremaining: 5m 24s\n600:\tlearn: 0.1692183\ttest: 0.6970333\tbest: 0.6968841 (590)\ttotal: 1m 56s\tremaining: 4m 30s\nbestTest = 0.6968841348\nbestIteration = 590\nShrink model to first 591 iterations.\nFinished training attr_1. Best score: 0.9441\n\nTraining model for attr_2\n0:\tlearn: 1.0511655\ttest: 1.0966241\tbest: 1.0966241 (0)\ttotal: 90.2ms\tremaining: 3m\n200:\tlearn: 0.1145008\ttest: 0.8310176\tbest: 0.8310176 (200)\ttotal: 14.1s\tremaining: 2m 6s\n400:\tlearn: 0.0657106\ttest: 0.7328267\tbest: 0.7328267 (400)\ttotal: 26.7s\tremaining: 1m 46s\n600:\tlearn: 0.0487301\ttest: 0.6967066\tbest: 0.6961157 (598)\ttotal: 38.5s\tremaining: 1m 29s\n800:\tlearn: 0.0392796\ttest: 0.6748287\tbest: 0.6748287 (800)\ttotal: 50.1s\tremaining: 1m 14s\n1000:\tlearn: 0.0327996\ttest: 0.6569683\tbest: 0.6566308 (999)\ttotal: 1m 1s\tremaining: 1m 1s\n1200:\tlearn: 0.0280499\ttest: 0.6399353\tbest: 0.6387018 (1184)\ttotal: 1m 13s\tremaining: 48.6s\n1400:\tlearn: 0.0247625\ttest: 0.6291477\tbest: 0.6288661 (1362)\ttotal: 1m 24s\tremaining: 36.1s\n1600:\tlearn: 0.0220776\ttest: 0.6134901\tbest: 0.6134901 (1600)\ttotal: 1m 35s\tremaining: 23.9s\n1800:\tlearn: 0.0200689\ttest: 0.6015895\tbest: 0.6015895 (1800)\ttotal: 1m 46s\tremaining: 11.8s\n1999:\tlearn: 0.0184916\ttest: 0.5955397\tbest: 0.5955397 (1999)\ttotal: 1m 57s\tremaining: 0us\nbestTest = 0.5955397258\nbestIteration = 1999\nFinished training attr_2. Best score: 0.9965\n\nTraining model for attr_3\n0:\tlearn: 1.0138628\ttest: 1.0211025\tbest: 1.0211025 (0)\ttotal: 57.6ms\tremaining: 1m 55s\n200:\tlearn: 0.1467954\ttest: 0.3017042\tbest: 0.3017042 (200)\ttotal: 7.55s\tremaining: 1m 7s\n400:\tlearn: 0.1025479\ttest: 0.2773435\tbest: 0.2773435 (400)\ttotal: 14.3s\tremaining: 57.2s\n600:\tlearn: 0.0802212\ttest: 0.2671481\tbest: 0.2671481 (600)\ttotal: 21s\tremaining: 48.9s\n800:\tlearn: 0.0645623\ttest: 0.2617828\tbest: 0.2617749 (799)\ttotal: 27.7s\tremaining: 41.5s\n1000:\tlearn: 0.0535464\ttest: 0.2586381\tbest: 0.2585663 (992)\ttotal: 34.3s\tremaining: 34.3s\n1200:\tlearn: 0.0454847\ttest: 0.2569598\tbest: 0.2569082 (1198)\ttotal: 41s\tremaining: 27.3s\n1400:\tlearn: 0.0393279\ttest: 0.2557641\tbest: 0.2556133 (1389)\ttotal: 47.6s\tremaining: 20.4s\nbestTest = 0.2555710629\nbestIteration = 1404\nShrink model to first 1405 iterations.\nFinished training attr_3. Best score: 0.9920\n\nTraining model for attr_4\n0:\tlearn: 0.9809960\ttest: 1.0135681\tbest: 1.0135681 (0)\ttotal: 52.7ms\tremaining: 1m 45s\nbestTest = 0.3985844066\nbestIteration = 51\nShrink model to first 52 iterations.\nFinished training attr_4. Best score: 0.9370\n\nTraining model for attr_5\n0:\tlearn: 1.7248739\ttest: 1.7622947\tbest: 1.7622947 (0)\ttotal: 343ms\tremaining: 11m 26s\n200:\tlearn: 0.3340047\ttest: 1.0216086\tbest: 1.0216086 (200)\ttotal: 1m 16s\tremaining: 11m 25s\n400:\tlearn: 0.1757761\ttest: 0.9517390\tbest: 0.9516985 (398)\ttotal: 2m 27s\tremaining: 9m 47s\n600:\tlearn: 0.1187350\ttest: 0.9292542\tbest: 0.9292236 (598)\ttotal: 3m 33s\tremaining: 8m 16s\n800:\tlearn: 0.0936433\ttest: 0.9197697\tbest: 0.9197697 (800)\ttotal: 4m 34s\tremaining: 6m 50s\n1000:\tlearn: 0.0790726\ttest: 0.9167249\tbest: 0.9161846 (951)\ttotal: 5m 33s\tremaining: 5m 32s\nbestTest = 0.9161845816\nbestIteration = 951\nShrink model to first 952 iterations.\nFinished training attr_5. Best score: 0.9887\n\nTraining model for attr_6\n0:\tlearn: 0.9850841\ttest: 0.9902333\tbest: 0.9902333 (0)\ttotal: 82.6ms\tremaining: 2m 45s\nbestTest = 0.2040181935\nbestIteration = 96\nShrink model to first 97 iterations.\nFinished training attr_6. Best score: 0.9541\n\nTraining model for attr_7\n0:\tlearn: 0.6139570\ttest: 0.6152109\tbest: 0.6152109 (0)\ttotal: 35.5ms\tremaining: 1m 10s\nbestTest = 0.1236835341\nbestIteration = 85\nShrink model to first 86 iterations.\nFinished training attr_7. Best score: 0.9432\n\nTraining model for attr_8\n0:\tlearn: 0.6498411\ttest: 0.6552197\tbest: 0.6552197 (0)\ttotal: 26.5ms\tremaining: 52.9s\n200:\tlearn: 0.0419966\ttest: 0.2339641\tbest: 0.2286052 (121)\ttotal: 3.03s\tremaining: 27.1s\nbestTest = 0.2286051787\nbestIteration = 121\nShrink model to first 122 iterations.\nFinished training attr_8. Best score: 0.9702\nFinished training model for Women Tshirts\n\nTraining model for category: Women Tops & Tunics\nPreparing data for training...\nTraining models for each attribute...\n\nTraining model for attr_1\n0:\tlearn: 2.3769241\ttest: 2.4221122\tbest: 2.4221122 (0)\ttotal: 436ms\tremaining: 14m 31s\n200:\tlearn: 0.4234537\ttest: 1.2669240\tbest: 1.2662677 (198)\ttotal: 1m 25s\tremaining: 12m 45s\n400:\tlearn: 0.2834887\ttest: 1.1509147\tbest: 1.1509147 (400)\ttotal: 2m 34s\tremaining: 10m 16s\n600:\tlearn: 0.2256145\ttest: 1.0997368\tbest: 1.0997368 (600)\ttotal: 3m 38s\tremaining: 8m 28s\n800:\tlearn: 0.1916045\ttest: 1.0681297\tbest: 1.0680213 (799)\ttotal: 4m 40s\tremaining: 7m\n1000:\tlearn: 0.1675257\ttest: 1.0471708\tbest: 1.0471708 (1000)\ttotal: 5m 42s\tremaining: 5m 41s\n1200:\tlearn: 0.1495688\ttest: 1.0350721\tbest: 1.0350189 (1199)\ttotal: 6m 43s\tremaining: 4m 28s\n1400:\tlearn: 0.1351582\ttest: 1.0267561\tbest: 1.0267561 (1400)\ttotal: 7m 44s\tremaining: 3m 18s\n1600:\tlearn: 0.1232152\ttest: 1.0190338\tbest: 1.0190338 (1600)\ttotal: 8m 45s\tremaining: 2m 10s\n1800:\tlearn: 0.1133906\ttest: 1.0160867\tbest: 1.0160708 (1799)\ttotal: 9m 45s\tremaining: 1m 4s\n1999:\tlearn: 0.1054688\ttest: 1.0108484\tbest: 1.0108484 (1999)\ttotal: 10m 45s\tremaining: 0us\nbestTest = 1.010848362\nbestIteration = 1999\nFinished training attr_1. Best score: 0.9582\n\nTraining model for attr_2\n0:\tlearn: 1.2962686\ttest: 1.2946314\tbest: 1.2946314 (0)\ttotal: 99.9ms\tremaining: 3m 19s\n200:\tlearn: 0.3203700\ttest: 0.5259282\tbest: 0.5259282 (200)\ttotal: 15.1s\tremaining: 2m 15s\n400:\tlearn: 0.2308417\ttest: 0.5068463\tbest: 0.5062984 (394)\ttotal: 29.1s\tremaining: 1m 55s\n600:\tlearn: 0.1877950\ttest: 0.5065043\tbest: 0.5048362 (536)\ttotal: 42.6s\tremaining: 1m 39s\nbestTest = 0.5048362288\nbestIteration = 536\nShrink model to first 537 iterations.\nFinished training attr_2. Best score: 0.9211\n\nTraining model for attr_3\n0:\tlearn: 0.6533875\ttest: 0.6554973\tbest: 0.6554973 (0)\ttotal: 41.7ms\tremaining: 1m 23s\n200:\tlearn: 0.1921176\ttest: 0.3057370\tbest: 0.3057370 (200)\ttotal: 5.27s\tremaining: 47.2s\n400:\tlearn: 0.1458763\ttest: 0.2916418\tbest: 0.2915863 (399)\ttotal: 10.1s\tremaining: 40.4s\n600:\tlearn: 0.1204037\ttest: 0.2876512\tbest: 0.2873534 (592)\ttotal: 14.9s\tremaining: 34.6s\n800:\tlearn: 0.1034322\ttest: 0.2839634\tbest: 0.2837702 (789)\ttotal: 19.5s\tremaining: 29.2s\n1000:\tlearn: 0.0901559\ttest: 0.2826709\tbest: 0.2826464 (989)\ttotal: 24.2s\tremaining: 24.1s\n1200:\tlearn: 0.0800704\ttest: 0.2826132\tbest: 0.2821745 (1112)\ttotal: 28.8s\tremaining: 19.2s\nbestTest = 0.2821745149\nbestIteration = 1112\nShrink model to first 1113 iterations.\nFinished training attr_3. Best score: 0.9822\n\nTraining model for attr_4\n0:\tlearn: 1.8215833\ttest: 1.8241683\tbest: 1.8241683 (0)\ttotal: 468ms\tremaining: 15m 36s\n200:\tlearn: 0.3230915\ttest: 0.5760127\tbest: 0.5760127 (200)\ttotal: 1m 22s\tremaining: 12m 16s\n400:\tlearn: 0.2263431\ttest: 0.5342935\tbest: 0.5342935 (400)\ttotal: 2m 30s\tremaining: 9m 58s\n600:\tlearn: 0.1786226\ttest: 0.5172125\tbest: 0.5172069 (598)\ttotal: 3m 35s\tremaining: 8m 22s\n800:\tlearn: 0.1488076\ttest: 0.5116864\tbest: 0.5115781 (798)\ttotal: 4m 41s\tremaining: 7m\n1000:\tlearn: 0.1297417\ttest: 0.5097179\tbest: 0.5096690 (998)\ttotal: 5m 45s\tremaining: 5m 44s\n1200:\tlearn: 0.1147516\ttest: 0.5094091\tbest: 0.5091282 (1176)\ttotal: 6m 49s\tremaining: 4m 32s\nbestTest = 0.5091282436\nbestIteration = 1176\nShrink model to first 1177 iterations.\nFinished training attr_4. Best score: 0.9805\n\nTraining model for attr_5\n0:\tlearn: 0.6469311\ttest: 0.6689327\tbest: 0.6689327 (0)\ttotal: 109ms\tremaining: 3m 37s\nbestTest = 0.579261202\nbestIteration = 19\nShrink model to first 20 iterations.\nFinished training attr_5. Best score: 0.8905\n\nTraining model for attr_6\n0:\tlearn: 1.0203728\ttest: 1.0208569\tbest: 1.0208569 (0)\ttotal: 87.9ms\tremaining: 2m 55s\n200:\tlearn: 0.1352913\ttest: 0.3151590\tbest: 0.3151590 (200)\ttotal: 13.1s\tremaining: 1m 57s\nbestTest = 0.3118522935\nbestIteration = 272\nShrink model to first 273 iterations.\nFinished training attr_6. Best score: 0.9500\n\nTraining model for attr_7\n0:\tlearn: 1.5603550\ttest: 1.5643952\tbest: 1.5643952 (0)\ttotal: 210ms\tremaining: 7m\n200:\tlearn: 0.2008403\ttest: 0.3545065\tbest: 0.3545065 (200)\ttotal: 35.2s\tremaining: 5m 14s\n400:\tlearn: 0.1411530\ttest: 0.3356654\tbest: 0.3356654 (400)\ttotal: 1m 6s\tremaining: 4m 23s\n600:\tlearn: 0.1092194\ttest: 0.3270932\tbest: 0.3270932 (600)\ttotal: 1m 36s\tremaining: 3m 44s\n800:\tlearn: 0.0886528\ttest: 0.3244921\tbest: 0.3244800 (799)\ttotal: 2m 6s\tremaining: 3m 9s\n1000:\tlearn: 0.0742162\ttest: 0.3232261\tbest: 0.3230860 (971)\ttotal: 2m 36s\tremaining: 2m 36s\n1200:\tlearn: 0.0634426\ttest: 0.3228897\tbest: 0.3228081 (1157)\ttotal: 3m 6s\tremaining: 2m 3s\nbestTest = 0.3227369036\nbestIteration = 1269\nShrink model to first 1270 iterations.\nFinished training attr_7. Best score: 0.9929\n\nTraining model for attr_8\n0:\tlearn: 1.2795451\ttest: 1.3095761\tbest: 1.3095761 (0)\ttotal: 112ms\tremaining: 3m 44s\n200:\tlearn: 0.1599025\ttest: 0.5014834\tbest: 0.5003502 (195)\ttotal: 16.9s\tremaining: 2m 31s\n400:\tlearn: 0.1174373\ttest: 0.4683691\tbest: 0.4683691 (400)\ttotal: 30.7s\tremaining: 2m 2s\n600:\tlearn: 0.0957315\ttest: 0.4479606\tbest: 0.4479606 (600)\ttotal: 44.2s\tremaining: 1m 42s\n800:\tlearn: 0.0818412\ttest: 0.4341081\tbest: 0.4340923 (797)\ttotal: 57.5s\tremaining: 1m 26s\n1000:\tlearn: 0.0706130\ttest: 0.4262552\tbest: 0.4255649 (978)\ttotal: 1m 11s\tremaining: 1m 10s\n1200:\tlearn: 0.0621672\ttest: 0.4213217\tbest: 0.4213217 (1200)\ttotal: 1m 24s\tremaining: 56.1s\n1400:\tlearn: 0.0553182\ttest: 0.4166520\tbest: 0.4165165 (1398)\ttotal: 1m 37s\tremaining: 41.8s\n1600:\tlearn: 0.0493918\ttest: 0.4134187\tbest: 0.4127416 (1547)\ttotal: 1m 51s\tremaining: 27.7s\n1800:\tlearn: 0.0448123\ttest: 0.4110293\tbest: 0.4110293 (1800)\ttotal: 2m 4s\tremaining: 13.8s\n1999:\tlearn: 0.0406597\ttest: 0.4067924\tbest: 0.4067924 (1999)\ttotal: 2m 17s\tremaining: 0us\nbestTest = 0.406792408\nbestIteration = 1999\nFinished training attr_8. Best score: 0.9878\n\nTraining model for attr_9\n0:\tlearn: 1.2999026\ttest: 1.3065293\tbest: 1.3065293 (0)\ttotal: 175ms\tremaining: 5m 48s\n200:\tlearn: 0.2108996\ttest: 0.4002678\tbest: 0.4002678 (200)\ttotal: 26.4s\tremaining: 3m 56s\n400:\tlearn: 0.1442575\ttest: 0.3801242\tbest: 0.3801242 (400)\ttotal: 49.7s\tremaining: 3m 18s\n600:\tlearn: 0.1134934\ttest: 0.3785509\tbest: 0.3779386 (528)\ttotal: 1m 12s\tremaining: 2m 48s\nbestTest = 0.3779386351\nbestIteration = 528\nShrink model to first 529 iterations.\nFinished training attr_9. Best score: 0.9493\n\nTraining model for attr_10\n0:\tlearn: 1.6242707\ttest: 1.6306753\tbest: 1.6306753 (0)\ttotal: 135ms\tremaining: 4m 28s\n200:\tlearn: 0.4684727\ttest: 0.6598020\tbest: 0.6598020 (200)\ttotal: 20.6s\tremaining: 3m 4s\n400:\tlearn: 0.3441352\ttest: 0.5985994\tbest: 0.5985994 (400)\ttotal: 39.6s\tremaining: 2m 37s\n600:\tlearn: 0.2754286\ttest: 0.5706599\tbest: 0.5706599 (600)\ttotal: 57.9s\tremaining: 2m 14s\n800:\tlearn: 0.2311037\ttest: 0.5545629\tbest: 0.5545629 (800)\ttotal: 1m 15s\tremaining: 1m 53s\n1000:\tlearn: 0.1994576\ttest: 0.5450659\tbest: 0.5449807 (997)\ttotal: 1m 33s\tremaining: 1m 33s\n1200:\tlearn: 0.1748958\ttest: 0.5387799\tbest: 0.5387799 (1200)\ttotal: 1m 51s\tremaining: 1m 14s\n1400:\tlearn: 0.1556649\ttest: 0.5340714\tbest: 0.5340534 (1399)\ttotal: 2m 8s\tremaining: 55.1s\n1600:\tlearn: 0.1396430\ttest: 0.5315795\tbest: 0.5314954 (1592)\ttotal: 2m 26s\tremaining: 36.5s\n1800:\tlearn: 0.1268665\ttest: 0.5292223\tbest: 0.5291766 (1792)\ttotal: 2m 43s\tremaining: 18.1s\n1999:\tlearn: 0.1163625\ttest: 0.5284390\tbest: 0.5284390 (1999)\ttotal: 3m\tremaining: 0us\nbestTest = 0.5284389957\nbestIteration = 1999\nFinished training attr_10. Best score: 0.9850\nFinished training model for Women Tops & Tunics\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_images = '/kaggle/input/visual-taxonomy/test_images'\ntest_df = pd.read_csv('/kaggle/input/visual-taxonomy/test.csv')  \ntest_df['image_path'] = test_df['id'].apply(lambda x: os.path.join(test_images, f\"{str(x).zfill(6)}.jpg\"))\ntest_predictions = pipeline.fill_predictions(test_df)\ntest_predictions = test_predictions[['id', 'Category', 'len', 'attr_1', 'attr_2', 'attr_3', 'attr_4',\\\n                                     'attr_5', 'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10']]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}